---
title: "Piltide klassifitseerimine eeltreenitud mudeliga - GPU"
output: html_notebook
---

Testi deep learningut, et kinnisvara pilte klassifitseerida
Põhineb Deep learning with R raamatu scriptil: https://github.com/jjallaire/deep-learning-with-r-notebooks/blob/master/notebooks/5.3-using-a-pretrained-convnet.Rmd

Käsud uue GPU instance käivitamise järel seadistusteks
```{r}
# library(RStudioAMI)
# 
# # Süngi Dropboxi deep_learning kaust
# linkDropbox()
# 
# excludeSyncDropbox("*")
# 
# includeSyncDropbox("deep_learning")
# 
# 
# # installi paketid
# ## Tensorflow
# install.packages("tensorflow")
# library("tensorflow")
# install_tensorflow(version = "gpu")
# 
# # Keras
# install.packages("keras")
# library("keras")
# install_keras(tensorflow = "gpu")
# 
# # Muud
# i
# 
# # magick paketi installimiseks terminalis:
# 
# sudo add-apt-repository -y ppa:opencpu/imagemagick
# sudo apt-get update
# sudo apt-get install -y libmagick++-dev
# 
# # seejärel installi magick
# install.packages("magick")

```


Lae paketid ja üks näidis pilt
```{r}
library(keras)
library(tidyverse)
library(magick)

# random pilt
image_read("data/train/kook/57917262.jpg")

# kuva numbrid komakohaga
options(scipen = 99)
```


Pane paika parameetrid
```{r}
# tubade list
tuba_list <- fs::dir_ls("data/train") %>% 
  as.character() %>% 
  str_replace("data/train/", "")

# klassifitseeritavate tubade arv
output_n <- length(tuba_list)

# muuda pildid väiksemaks, et mudel oleks kiirem
img_width <- round(383 / 2, 0)
img_height <- round(218 / 2, 0)
target_size <- c(img_height, img_width)

# RGB = 3 channels
channels <- 3

# piltide path train ja validation kaustas
train_image_files_path <- "data/train"
valid_image_files_path <- "data/validation/"
```

Muuda piltide pixel väärtused nii, et need oleks 0 ja 1 vahel
```{r}
# scale piltide andmed
# muuda igas epochis ka pisut pilte, et vältida overfittingut
train_data_gen = image_data_generator(
  rescale = 1/255,
  rotation_range = 40,
  width_shift_range = 0.2,
  height_shift_range = 0.2,
  shear_range = 0.2,
  zoom_range = 0.2,
  horizontal_flip = TRUE,
  fill_mode = "nearest"
)

# scale validation piltide andmed
valid_data_gen <- image_data_generator(
  rescale = 1/255
  )  
```

Lae pildid mälusse ja muuda nende suurust
```{r}
# training images
train_image_array_gen <- flow_images_from_directory(train_image_files_path, 
                                          train_data_gen,
                                          target_size = target_size,
                                          class_mode = "categorical",
                                          classes = tuba_list)

# validation images
valid_image_array_gen <- flow_images_from_directory(valid_image_files_path, 
                                          valid_data_gen,
                                          target_size = target_size,
                                          class_mode = "categorical",
                                          classes = tuba_list)
```

Kui palju erinevaid tubade pilte train kaustas on?
```{r}
table(factor(train_image_array_gen$classes))
train_image_array_gen$class_indices
```

Salvesta tubade indeksid
```{r}
tuba_classes_indices <- train_image_array_gen$class_indices

save(tuba_classes_indices, 
     file = "data/tuba_classes_indices_gpu.RData")
```

Seadista deep learning mudeli parameetrid
```{r}
# number of training samples
train_samples <- train_image_array_gen$n

# number of validation samples
valid_samples <- valid_image_array_gen$n

# define batch size and number of epochs
batch_size <- 32
epochs <- 20
```


Lae VGG16 eeltreenitud mudel
```{r}
conv_base <- application_vgg16(
  weights = "imagenet",
  include_top = FALSE,
  input_shape = c(img_height, img_width, 3)
)
```

Seadista mudel
```{r}
model <- keras_model_sequential() %>% 
  conv_base %>% 
  layer_flatten() %>% 
  layer_dense(units = 256, activation = "relu") %>%  # proovi ka units = 32
  layer_dense(units = 6, activation = "softmax")

summary(model)
```


```{r}
cat("This is the number of trainable weights before freezing",
    "the conv base:", length(model$trainable_weights), "\n")
```

```{r}
freeze_weights(conv_base)
```

```{r}
cat("This is the number of trainable weights after freezing",
    "the conv base:", length(model$trainable_weights), "\n")
```

Treeni mudel nii, et võta aluseks eeltreenitud mudel ja lisa sinna oma piltide andmed
```{r}
# compile
model %>% compile(
  loss = "categorical_crossentropy",
  optimizer = optimizer_rmsprop(lr = 0.0001),
  metrics = "accuracy"
)

# fit
hist <- model %>% fit_generator(
  # training data
  train_image_array_gen,
  
  # epochs
  steps_per_epoch = as.integer(train_samples / batch_size), 
  epochs = epochs, 
  
  # validation data
  validation_data = valid_image_array_gen,
  validation_steps = as.integer(valid_samples / batch_size),
  
  # print progress
  verbose = 2
)
```


Salvesta mudeli tulemused
```{r}
save_model_hdf5(model, "data/toad_gpu.h5")
```

Plot results
```{r}
plot(hist)
```


## Lisa fine-tunig mudelile

```{r}
model <- load_model_hdf5("data/toad_gpu.h5", custom_objects = NULL, compile = TRUE) 
```


```{r}
unfreeze_weights(conv_base, from = "block3_conv1")

model %>% compile(
  loss = "categorical_crossentropy",
  optimizer = optimizer_rmsprop(lr = 0.0001),
  metrics = "accuracy"
)

# fit
hist <- model %>% fit_generator(
  # training data
  train_image_array_gen,
  
  # epochs
  steps_per_epoch = as.integer(train_samples / batch_size), 
  epochs = 50, 
  
  # validation data
  validation_data = valid_image_array_gen,
  validation_steps = as.integer(valid_samples / batch_size),
  
  # print progress
  verbose = 2
)
```


Salvesta mudeli tulemused
```{r}
save_model_hdf5(model, "data/toad_gpu_tuned.h5")
```

Plot results
```{r}
plot(hist)
```

### Ennusta eeltreenitud mudeli põhjal tulemusi

Funktsioon pilti labeli ennustamiseks, et testida tulemusi
https://github.com/uday97/food-recognition/blob/5e5c739e5f24f9355180105a544f31a0e7153a82/model_prediction.R
```{r}
#lae tubade mudel, et selle abil ennustusi teha
toad_model <- load_model_hdf5("data/toad_gpu_tuned.h5", custom_objects = NULL, compile = TRUE) 

prediction <- function(x){
  img <- image_load(x, target_size = c(img_height, img_width))
  data <- image_to_array(img)
  dim(data) <- c(1, img_height, img_width, 3)
  ans <- predict(toad_model, data)
  return(round(ans, 2))
}
```

Lae toa indeksi ja nime seos
```{r}
load(file = "data/tuba_classes_indices_gpu.RData")
```


Kuva tubade indeksid, mis mudelis on kasutusel
```{r}
tuba_classes_indices %>% 
  as_tibble() %>% 
  gather("tuba", "indeks") %>% 
  arrange(indeks) %>% 
  mutate(id = indeks + 1) %>% 
  select(id, tuba)
```

Ennusta pildi tag
```{r}
random_pilt <- list.files("data/kuulutuste_pildid_backup/kuulutuste_pildid_backup/", full.names = TRUE) %>% 
  as_tibble() %>% 
  sample_n(1) %>% 
  pull(value)

image_read(random_pilt)

prediction(random_pilt) 
```

